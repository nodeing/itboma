# 数据存储相关概念

### 计算机中的进制

先理解一下，什么是进制？进制就是进位计数制，是人为定义的带进位的计数方法，我们生活中最常用的就是十进制，我们来看十进制的表示

```
数字0-9组成，一共十个数，满10进1
如果要表示第10个数，9已经是最大数字了，需要往前进一位
```

回顾了十进制的机制，那么二进制就好理解了

```
数字0-1组成，一共2个数，满2进1
如果要表示十进制的2，因为1是最大数字了，所以要表示2，需要往前进一位
意味着2进制里面的2表示成这样：10
```

思考一下，如果十进制中的 12，用二进制应该如何表示？

```
1100
```

以此类推，八进制

```
数字0-7组成，一共8个数，满8进1
```

十六进制

```
数字0-9，字母a-f组成，满16进1
```

进制转换工具：[点击进入](https://tool.oschina.net/hexconvert/)

### 数据存储单位

在计算机中，数据存储的基本单位是字节，即 Byte，这是硬件所访问到的最小单位，常见的存储单位有，bit（位）、B（字节）、KB（千字节）、MB（兆字节）、GB（千兆字节），它们之间的换算关系如下：

```
1B=8bit
1KB=1024B
1MB=1024KB
1GB=1024MB
```

最小单位和基本单位这两个概念有差异，不要搞混了

计算机中数据的最小单位是位，即 bit
计算机中数据的基本单位是字节，即 Byte

cpu 处理速度非常快，硬盘的处理速度远远落后于 cpu 的处理速度，如果直接让 cpu 去处理硬盘上的数据就会让整个计算机的运行速度降低，因此，cpu 处理数据是从内存中去读取的，内存的速度比硬盘的速度快很多，我们以运行 QQ 程序为例，讲一下 cpu、内存、硬盘的关系

```
1.硬盘中安装了一个qq程序
2.双击qq程序图标，cpu接收到一条命令，把qq程序加载到内存
3.cpu开始执行qq程序，程序执行起来后，CPU 可以让 QQ 程序显示在我们的在显示器上。也就是你看到了 QQ 程序运行起来了
```

总结：

:::tip
CPU 只能直接处理内存数据，不能直接处理硬盘数据。硬盘数据必须先调入内存条中才可以运行。内存中存储数据的最小单位是“位（Bit）”
:::

### 编码的故事

先理解两个概念

```
什么是编码？
什么是解码？
```

什么是编码？先明确两个前提

```
计算机： 只能理解0和1，数据的最小单位是位（bit）
人类：理解的语言文字由英文字母、汉语汉字、标点符号字符、阿拉伯数字等等很多的字符构成的字符集
```

举个例子：

```
人类认识： 字母A、B、C
计算机认识：0和1
```

那么问题来了，如果要让计算机按照人类的意愿进行工作，如何让计算机理解人类的文字呢？

解决方案是做一套编码规则，即让人类认识的字符和计算机理解的二进制 0、1 之间产生一一对应关系，例如：

![20221204083210](https://nodeing-com-1252923609.cos.ap-chengdu.myqcloud.com//document20221204083210.png)

上面图中，使用了 0-127 这 128 个数字和人类常用的字符做了一一对应的绑定，例如：

```
65 -- A
66 -- B
67 -- C
127 -- DEL
```

其中，每个数字都是可以用二进制数表示的

```
01000001 -- A
01000010 -- B
01000011 -- C
01111111 -- DEL
```

计算机在美国发明，早期使用到的符号并不多，因此，美国人做了上面这套编码系统，然后取名叫做 ASCII

ASCII (American Standard Code for Information Interchange)：美国信息交换标准代码是基于拉丁字母的一套电脑编码系统，主要用于显示现代英语和其他西欧语言。

总结：

:::tip
编码就是把人类所使用的这些字符集转换为计算机所能理解的二级制码，这个过程就是编码
:::

何为解码？当有了上面 ASCII 这套编码规则，那么计算机就可以将人类的语言转化成自己的语言存储起来，例如：

```
A -- 存储成 --> 01000001
B -- 存储成 --> 01000010
```

如果把存储起来的这些二进制数据，读取出来，并且转化成人类认识的语言，这个过程就是解码

:::tip
注意：编码表（字符集）本质就是计算机和人类语言之间的一一对应关系
:::

![20221204085649](https://nodeing-com-1252923609.cos.ap-chengdu.myqcloud.com//document20221204085649.png)

随着计算机的普及，全世界各个国家都有使用计算机的需求，美国人最初搞定这套编码规则只有 128 个符号，很显然不符合其他国家的人的使用需求，例如：中国、欧洲，都有自己常用的语言文字，这个时候各自都需要一套字符集，于是欧洲人搞了一套出来，取名 Latin-1，中国人搞了一套出来，取名《信息交换用汉字编码字符集》，标号 GB 2312—1980，[点击查询](https://toolhelper.cn/Encoding/GB2312)

具体按照什么样的方式去生成的字符集没必要深入研究，你只需要知道字符集就是人类语言文字和计算机语言有一一对应关系即可

每个国家都可以有自己的字符集，五花八门的，这会有一个问题，装有不同编码系统的计算机之间通信会比较麻烦，常常不知道对方在说什么，这个很容易理解，就相当于两个间谍，靠密码本才能正确传递情报，你要是中途把密码本换了，对方肯定是解码不出来的，当解码不出来的时候，就会出现一些莫名其妙的符号，这就是乱码
举个例子：

下面写的代码是基于 utf-8 编码的

![20221204091811](https://nodeing-com-1252923609.cos.ap-chengdu.myqcloud.com//document20221204091811.png)

我接下来，换一个编码

![20221204091908](https://nodeing-com-1252923609.cos.ap-chengdu.myqcloud.com//document20221204091908.png)

第一次写代码的时候，使用的是 utf-8 存储的，我换一个编码 us-ascii 来解码显示，就会出现乱码

为了让各个国家，各种语言之间的文本信息处理更加方便，不出现乱码问题，需要一个适用于全球的统一字符编码，因此，ISO 国际标准化组织提出了一种新的方案 Unicode，这种方案实现了跨语言、跨平台的文本转换和处理需求

上面我们提到了 utf-8 编码，这个又是什么鬼？要理解这个问题，需要先来理解两个概念

```
1.字符代码：某个字符在字符集中的序号，例如：A在ASCII码表中的序号是65

2.字符编码：传输或者存储过程中用于表示字符的以字节为单位的二进制序列
```

在 ASCII 字符集中，字符代码和字符编码是一致的，即 65 这个字符代码，通过编码存储在硬盘上的字符编码是 65 的二进制表示，即 01000001，占一个字节

在 GB2312 编码系统中，字符代码和字符编码也是一致的，但是汉字比较多，一个需要更大的字符代码（码表中的序号），二这个更大的序号如果转化成二进制存储在硬盘上，需要占更多字节，例如：序号 35534（十进制） --> 10001010 11001110(二进制，16 位，2 个字节)

Unicode 方案做到跨语言、跨平台，收入的字符非常多，它里面包括两个方面的内容

```
字符集： 为每一个字符分配一个唯一的ID（学名为码位/码点/Code Point）。
编码规则： 将 码位 转换为 字节序列 的规则。
```

unicode 字符集中的字符代码是用 4 个字节来表示的，如果还是让字符代码和字符编码一致，那么每个字符编码出来都会占用 4 个字节，如果传输的是一个字母 A，这个字母 A 本来在 ASCII 码中只需要 1 个字节就可以存了，但是还是用了 4 个字节来存，这就浪费了 3 个字节的空间，显然不是最佳方案

基于上面说到的问题，就需要在字符代码和字符编码之间进行再次编码，这就是 UTF-8、UTF-16 等编码方式出现的原因

UTF-8 将不同范围的字符代码，转化成不同范围的字符编码，而不是固定的 4 个字节，举个例子：0-127 范围的字符代码，转换出来的字符编码就是 1 个字节，而常用汉字使用 3 个字节来进行编码

:::tip
总结：字符编码，我们选择 utf-8 即可
:::
